<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="this is the second essay from the essay page of erin harper's website"
    />
    <title>essay one</title>
    <link rel="stylesheet" href="../css files/style.css" />
    <link rel="stylesheet" href="../css files/normalize.css" />
    <script
      src="https://kit.fontawesome.com/161eb88f79.js"
      crossorigin="anonymous"
    ></script>
  </head>
  <body>
    <a href="#" class="to-top"><i class="fa fa-thin fa-arrow-up"></i></a>
    <script src="js files/scroll.js"></script>

    <input type="checkbox" id="check" />
    <label for="check">
      <i class="fa fa-thin fa-bars" id="btn"></i>
      <i class="fa fa-thin fa-xmark" id="cancel"></i>
    </label>
    <div class="sidebar">
      <header>menu</header>
      <a href="../index.html"><span>home</span></a>
      <a href="../portfolio.html"><span>portfolio</span></a>
      <a href="../about.html"><span>about</span></a>
      <a href="../contact.html"><span>contact</span></a>
      <a href="../devblogs.html"><span>devblogs</span></a>
      <a href="../essay.html"><span>essay</span></a>
      <a href="../design.html"><span>design</span></a>
    </div>

    <section class="essayheader">
      <h1>essay two</h1>
    </section>

    <article class="row">
      <div class="blogleft">
        <p>
          In the current digital age, the spread of algorithmic culture and
          artificial intelligence (AI) to the Internet has resulted in major
          shifts in the way we consume information, engage with people, and
          shape our online experiences. However, with the growing popularity of
          algorithms and AI systems, this new age has not been without debate
          and ethical implications. As AI is increasingly being integrated into
          our daily lives, ethical issues for businesses and individuals become
          more difficult. (Tanne 2022) In this essay, we will be exploring the
          impact of algorithmic culture and AI on the internet in conjunction
          with the statement on AI Risk published by Centre for Artificial
          Intelligence Safety (CAIS) and other relevant sources whilst using the
          ‘Ethical Internet Framework’ to analyse it further critically.
        </p>
        <p>
          Before we dive into the Ethics part of our analysis, let us look at
          what CAIS is, who released it, why was it signed and by whom. The CAIS
          is a research and field-building non-profit organisation (NPO) wherein
          their aim is to eliminate societal-scale dangers associated with AI
          through safety research, the development of a field of AI safety
          researchers, and advocacy for safety standards. On May 30th, 2023, a
          statement regarding the risk of AI was released, this was then signed
          by over 350 people who were seen to be AI experts, philosophers,
          scientists, ethicists, economists, legal scholars, and the list goes
          on. This statement was signed for the following concern, which is
          stated above the signatories, ‘Mitigating the risk of extinction from
          AI should be a global priority alongside other societal-scale risks
          such as pandemics and nuclear war’.
        </p>
        <p>
          When looking at AI, like anything done there are risks involved, one
          of the risks according to Technology reported McCallum is that the
          exponential growing rate of AI is transforming multiple aspects of
          modern life inflicting fear that it may be used for malicious or job
          threatening purposes. (McCallum 2023) CAIS feels the same way about
          it, to the point where they have even categorised their AI risks into
          eight categories which are the following: Weaponization,
          Misinformation, Proxy Gaming, Enfeeblement, Value Lock-in, Emergent
          Goals, Deception, and lastly Power-Seeking Behaviour. (8 Examples of
          AI Risk 2023)
        </p>
        <p>
          Before diving further into these eight risks, let us look at defining
          what internet ethics are. This term can be seen to be very broad hence
          why it is important for us to analyse and understand it. According to
          Gill it refers to an examination of the role of the internet in what
          philosophers refer to as the evolution of the good life being the life
          we want for society. (Gill 2021) Basically an acceptable behaviour for
          using the internet. Thereafter linking to computer ethics which is
          moral principles that govern the way we as users on what is acceptable
          whilst using computers.
        </p>
        <p>
          As mentioned in the above, we will be diving more in depth into
          exploring the eight categories, however seeing that these categories
          might not all necessarily link to internet ethics, I have decided to
          pick three that I feel relate the most and can provide use to the
          discussion. They are Weaponization, Misinformation and Value Lock-In
          while touching on the issue of privacy which is not mentioned in the
          eight but plays a crucial role in internet ethics.
        </p>
        <p>
          To begin let us start by looking at Misinformation, as we know already
          just by simple having a phone, information often gets misinterpreted
          and informed, now with AI being the biggest part in society wherein
          users use applications such as ChatGPT for everything however that is
          where the problem begins. As we known ChatGPT was released in November
          2022 on the platform known as OpenAI. An article written by Hsu and
          Thompson state their major concern with ChatGPT and providing false
          narratives. The reason for these false narratives is because this
          platform was created by humans hence the disinformation comes from the
          creators which can be difficult to wrangle. (Hsu & Thompson 2023)
        </p>
        <p>
          Furthermore co-chief executive of NewsGuard, Gordin Crovitz stated
          that this AI tool will be the biggest tool yet when it comes to
          spreading misinformation on the internet, and his reason behind it
          makes sense because why trust a tool that is not 100% the truth.
          Therefore it is critical to disseminate accurate and balanced
          information on artificial intelligence and its ethical implications.
          As if AI can make mistakes like we as humans do (Can we trust
          artificial intelligence?), this further enhances the spread of
          misinformation which is seen to lead directly into our next part of
          what CAIS mentions as another factor of AI risk, which is
          weaponization.
        </p>
        <p>
          When looking at Weaponization, according to CAIS it refers to
          malicious users that can repurpose AI to become exceedingly
          destructive while posing an existential threat and increasing the
          likelihood of political upheaval. (8 Examples of AI Risk 2023) This
          results in people using AI for their own personal gain or put other
          people at risk. Some examples of the weaponization that AI can bring
          about include the following, being used for cyber warfare and
          autonomous weapons.
        </p>
        <p>
          Cyber Warfare is the deployment of computer viruses or
          denial-of-service assaults by a nation-state or international
          organization to attack and attempt to harm another nation's computers
          or information networks. (Cyber warfare) However with this in use,
          major powers are using this kind of weaponization to develop and
          deploy physically destructive weapons, that in the end cause harm to
          innocent lives for it affects more than one person (Marijan 2022)
        </p>
        <p>
          Something that really struck me was whilst reading the article by Paul
          is how people made use of AI to help with their decisions, which
          already brings across a fault. However it was reported that a man in
          Belgium died by suicided after a chatbot encouraged him to take his
          own life (Paul 2023) therefore being used in a way to influence users’
          thoughts and mannerisms which brings out the manipulation within the
          weaponization. For remember these bots were created by someone who had
          a set mindset/certain value which to some extent make it biased.
        </p>
        <p>
          The last part out of the 8 risks that I wanted to touch on is Value
          Lock-In. This is where AI and algorithms can lock you as the user to
          certain platforms or services based on the algorithmic systems that
          are displayed. A common area where this can be seen is on your social
          media applications such as Instagram and TikTok for when you wonder
          why your video or image get a certain number of likes, it is all
          dependent on the algorithmic behaviour. With the above mentioned in
          mind when we look at what the term ethics refers to it is seen as the
          following, well-founded moral norms that dictate what humans should
          do, generally in terms of rights, duties, societal advantages,
          fairness, or special qualities.(Velasquez et al.)
        </p>
        <p>
          Therefore while utilise these AI tools or creating them we should make
          sure they address these ethical values mentioned above to ensure that
          AI and algorithms serve in the best interest of individuals and in
          society without being used to cause destruction etc. To conclude the
          above-mentioned information, it is important to take note of the
          impact of algorithmic culture and AI on the internet, along with the
          ethical implications that come with it. As we can gain a more
          comprehensive understanding. These few risks that were spoken about in
          the essay were just a few out of all the risks that come with AI
          therefore highlighting the importance of incorporating ethical
          concepts into AI system design, deployment, and governance to assure
          alignment with society norms, protect the users, prevent against
          malicious usage and misinformation. Even as we approach this new age
          of technology being AI while being happy about what AI can do for us,
          we must not forget about the risks that come with it for that is what
          will cause our downfall as a human race.
        </p>
        <p>References:</p>
        <p>
          Can we trust artificial intelligence? n/d. Caltech Science Exchange.
          Online. Available at:
          https://scienceexchange.caltech.edu/topics/artificial-intelligence-research/trustworthy-ai#:~:text=Uncertainty%20Measures,a%20highway%20for%20the%20sky
          Date Accessed: 24 June 2023. <br />
          Center for AI safety (CAIS). 2023. Center for AI Safety (CAIS).
          Online. Available at: https://www.safe.ai/ Date Accessed: 21 June
          2023. <br />
          Cyber warfare. n/d. RAND Corporation. Online. Available at:
          https://www.rand.org/topics/cyber-warfare.html Date Accessed: 24 June
          2023. <br />
          Gill, J. 2021. What is internet ethics? rules for everyone, AOFIRS.
          Online. Available at:
          https://aofirs.org/articles/internet-ethics-for-everyone Date
          Accessed: 22 June 2023. <br />
          Hsu, T. & Thompson, S.A. 2023. Disinformation researchers raise alarms
          about A.I. Chatbots, The New York Times. Online Available at:
          https://www.nytimes.com/2023/02/08/technology/ai-chatbots-disinformation.html
          Date Accessed: 23 June 2023. <br />
          Marijan, B. 2022. Ai-influenced weapons need better regulation,
          Scientific American. Online. Available at:
          https://www.scientificamerican.com/article/ai-influenced-weapons-need-better-regulation/
          Date Accessed: 24 June 2023. <br />
          McCallum, S. 2023. What is ai, is it dangerous and what jobs are at
          risk? BBC News. Online. Available at:
          https://www.bbc.com/news/technology-65855333 Date Accessed: 20 June
          2023. <br />
          Paul, K. 2023. Robot takeover? not quite. here’s what ai doomsday
          would look like, The Guardian. Online. Available at:
          https://www.theguardian.com/technology/2023/jun/03/ai-danger-doomsday-chatgpt-robots-fears
          Date Accessed: 23 June 2023. <br />
          Statement on AI Risk: AI experts and public figures express their
          concern about AI risk. 2023. Statement on AI Risk | CAIS. Online.
          Available at: https://www.safe.ai/statement-on-ai-risk Date Accessed:
          20 June 2023.
          <br />
          Tanne, S. 2022. Forging a future with ethical AI, Spiceworks. Online.
          Available at:
          https://www.spiceworks.com/tech/artificial-intelligence/guest-article/forging-a-future-with-ethical-ai/
          Date Accessed: 20 June 2023. <br />
          Velasquez, M. et al. n/d What is ethics? Markkula Center for Applied
          Ethics. Online. Available at:
          https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/what-is-ethics/#:~:text=First%2C%20ethics%20refers%20to%20well,%2C%20fairness%2C%20or%20specific%20virtues
          Date Accessed: 25 June 2023. <br />
          8 Examples of AI Risk. 2023. AI Risk | CAIS. Online. Available at:
          https://www.safe.ai/ai-risk Date Accessed: 22 June 2023.
        </p>
      </div>
    </article>
  </body>
</html>
